---
title: "Bland-Altman analysis"
author: "blandr v0.6.1"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
runtime: shiny
output: html_document
params:
    method1: NA
    method2: NA
---

```{r setup, include=FALSE}
library(blandr)
knitr::opts_chunk$set( echo = TRUE , cache=FALSE )
params$method1
params$method2
results <- blandr.statistics( method1 , method2 )
```

## Preamble

This is an autogenerated report from the blandr R library. This report relies on the data being supplied to be accurate. Whilst it tries to provide some information on the data provided, it *IS NOT* a replacement for proper review (and sense checks) of the data. It is also *NOT* a replacement for formal statistical advice.  

The *blandr report automated tool* is intended to be a tool for the start of exploration of the data generated. Statistical agreement (or lack of) does not mean that there is acceptable practical agreement: the level of acceptable agreement should be defined before this tool is used. All use of the statistics provided is at the user's own risk.

## Find this useful? Citation information

You can find the citation information through the usual R citation commands:
```{r}
citation("blandr")
```

The DOI will refer to all versions of blandr. If you need to cite specific releases DOIs, the full versioning information can be found at Zenodo (https://zenodo.org/record/824514), with the full source code at the blandr GitHub page (https://github.com/deepankardatta/blandr/).

## Interpreting the output

The two methods used in the comparison will be labelled "Method 1" and "Method 2". It is up to the user to understand which data they have supplied as these methods. The package always calculates the differences as "Method 1" minus "Method 2".

Questions to think about when interepreting the data include:

1. Should the two methods be compared?
2. Is the data correct?
3. *A priori*, what can be thought of as acceptable practical agreement?
4. In the data is there statistical agreement?
5. In the data is there practical agreement?
6. What conclusions can be drawn from the data?

A suggestion by Chhapola et al. (doi:10.1177/0004563214553438) on reporting the data includes:

1. correct representation of x-axis on Bland-Altman plot
2. representation and correct definition of limits of agreement (LOA)
3. reporting of confidence interval (CI) of LOA
4. comparison of LOA with a priori defined clinical criteria
5. evaluation of the pattern of the relationship between difference (y-axis) and average (x-axis)
6. measures of repeatability.

## Description of the plots

The dashed lines represent the summary Bland-Altman statistical data, namely: (1) bias, (2) upper limit of agreement, (3) lower limit of agreement. The dotted line (when present) represent confidence intervals for the summary statistics.

***

## Summary statistics of "Method 1"

```{r}
method1
summary(method1)
hist(method1)
```

***

## Summary statistics of "Method 2"

```{r}
method2
summary(method2)
hist(method2)
```

***

## Check of normality of differences

Bland & Altman suggest to create what is thought of as a standard Bland-Altman plot, the differences need to be normally distributed. We can assess this with histograms, QQ plots, or with the Shapiro-Wilk normality test. Do seek formal statistical advice for assumptions behind all these tests.

We can describe graphically the distribution of the differences. Further, a QQ plot can be generated - in general the scatter points should be as close to the line as possible to suggest the data is normally distributed.
```{r}
blandr.plot.normality( results )
blandr.plot.qq( results )
```

In the Shapiro-Wilk test the null hypothesis is that the data is normally distributed. If p>0.05, normality can be assumed.
```{r}
shapiro.test( results$differences )
```

***

## Plot comparison with best fit line to investigate for proportional bias

```{r}
blandr.draw ( method1 , method2 , ciDisplay = FALSE , plotProportionalBias = TRUE )
print(results$regression.equation)
```

***

## Bland-Altman analysis (with assumption of normal distribution of differences)

```{r}
# Uses one of the Jamovi functions as it gives you a nice table as well
# Although you can call the blandr.draw function for a ggplot as well
ba_data <- data.frame( method1 , method2 )
blandr::jamoviBAanalysis( data=ba_data , method1="method1" , method2="method2" )
```

***

## Additional comparison data

```{r}
blandr.method.comparison ( method1 , method2 , sig.level=0.95 )
```

***

## Raw data output of comparison statistics
```{r}
print(results)
```

***
